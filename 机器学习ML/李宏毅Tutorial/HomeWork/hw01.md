作业内容：根据前9的天气数据来预测第十天的天气的PM2.5的值



# 1、利用pandas读取csv中数据

```python
#首先要导包
import pandas as pd
#然后读取数据
data = pd.read_csv(filepath_or_buffer="D://movie.csv")
data = pd.read_csv('./train.csv', encoding = 'big5')
```

[矩阵的乘法与点积](https://blog.csdn.net/yl_best/article/details/86702200)，a向量=[1,2,3]，b向量=[4,5,6]。`a向量.b向量=1*4+2*5+3*6`，即为向量a在向量b上的投影，与b模长的乘积

数量积（又叫内积、点积dot product; scalar product）
$$
\overrightarrow{a}=(x_1,y_1)\ ,\overrightarrow{b}=(x_2,y_2)
\\
\overrightarrow{a}\mathbf{.} \overrightarrow{b}=x_1x_2+y_1y_2
$$


可以把矩阵乘$\textbf{C=AB} 中的\textbf{C}^{ij}$看作是矩阵A 的第i 行和矩阵B 的第j 列之间的点积。

# 2、梯度下降法实现线性回

### 梯度下降法：

![线性回归](https://i.loli.net/2021/03/12/KSrIHE6iW5LpJNa.png)

设：样本数为n个，参数个数为m个

1. 声明权重向量和迭代次数

2. 对于每次迭代：

   1. 预测值=输入参数组成的矩阵（矩阵大小n\*(m+1)，多加一列单位向量主要是为了bias）\*权重向量（Weight向量，为(m+1)\*1维）
   2. L=预测值-实际值（或者$ Loss=\sqrt{ \frac{\left ( y'-train_y\right )^{2}}{n}}$)
   3. 计算梯度，就是Loss对w求导

$$
Loss=(y-\hat{y})^{2}=(b+wx-\hat{y})^2
\\
gradient=\frac{\partial L}{\partial w}=2x^{T}(b+wx-y)=2x^{T}(y-\hat{y})=2x\cdot(y-\hat{y})
$$

3. weight向量=weight向量-学习速率*梯度

### 自适应梯度下降法：

![自适应梯度下降法.png](https://i.loli.net/2021/03/12/h3bLOeRgrQUAzw5.png)

![自适应梯度下降法原理.png](https://i.loli.net/2021/03/12/mukQtvbfyXNgDWh.png)

1. 声明权重向量和迭代次数
2. 声明一个prev_grad=0向量用来存储previous先前的梯度的平方和
3. 对于每次迭代：

   1. 预测值=输入参数组成的矩阵（矩阵大小n\*(m+1)，多加一列单位向量主要是为了bias）\*权重向量（Weight向量，为(m+1)\*1维）
   2. $Loss= \frac{\left ( \hat{y}-y\right )^{2}}{n}$（或者$ Loss=\sqrt{ \frac{\left ( \hat{y}-y\right )^{2}}{n}}$)
   3. 计算梯度$ gradient=2\vec{x}^T(y-\hat{y})$ #就是表示对Loss函数求w导，此时假设$Loss= \left ( y-\hat{y}\right )^{2}=\left (wx-\hat{y}\right )^{2}$，其中y为预测输出，$\hat{y}$为应该的输出，上式n为常量不影响loss的变化，所以考虑gradient的时候可以忽略。
   4. prev_grad=prev_grad+(gradient)^2
   5. weight向量=weight向量-学习速率*梯度/√(prev_grad)



# 3、源代码

```python
import sys
import pandas as pd
import numpy as np

# 下面的代码是从Google下载文件，此处下载到本地了就不需要这段文字了
'''from google.colab import drive
!gdown --id '1wNKAxQ29G15kgpBy_asjTcZRRgmsCZRm' --output data.zip
!unzip data.zip
# data = pd.read_csv('gdrive/My Drive/hw1-regression/train.csv', header = "infer", encoding = 'big5')
'''
data = pd.read_csv('csv/train.csv',header="infer", encoding='big5')#header="infer"意思就是说这个数据是有最上面一行的,'../csv/train.csv'其中../表示意思是上级目录

# data = data.iloc[1:5, 3:5]#选取第1-4行，第三到四列的数据，前闭后开
#df.iloc[[0, 2], [1, 3]]#选取第一行，第三行，第二列，第4列的数据
data = data.iloc[:, 3:]  # 意思就是选取每一行，选取3-最后  这么多列
print(data)
# print(data=='NR')
data[data == 'NR'] = 0  # 将data中数据等于'NR'的换为0
print(data)
raw_data = data.to_numpy()  # 将DataFrame的数据转为Numpy Array，不然不能使用直接使用[1:10,2:10],或者是使用data.iloc[1:10,2:20]
print(type(raw_data))
# 将每天的数据分开


month_data = {}  # 设置一个字典
for month in range(12):  # 循环拼12个月

    sample = np.empty([18, 480])  # 生成一个18行480列的numpy array
    for day in range(20):
        sample[:, day * 24: (day + 1) * 24] = raw_data[18 * (20 * month + day): 18 * (20 * month + day + 1),:]  # 将一个月中每天的24小时数据拼在一起
    month_data[month] = sample  # 所有的数据拼接成一个字典数据
print(month_data[0].shape, '---------')
# 设置一个12*471行，18*9列的ndarray
x = np.empty([12 * 471, 18 * 9], dtype=float)
# print(type(x),x.shape)
# 设置一个12*471行，18*9列的ndarray,即输入参数为18*9=162个，输出为1个，样本数为12*471=5652个
y = np.empty([12 * 471, 1], dtype=float)

for month in range(12):
    for day in range(20):
        for hour in range(24):
            if day == 19 and hour > 14:  # 一个月的最后一个小时
                continue
            x[month * 471 + day * 24 + hour, :] = month_data[month][:, day * 24 + hour: day * 24 + hour + 9].reshape(1,
                                                                                                                     -1)  # reshape(行数，列数)，-1表示unspecified value为未指定的值
            y[month * 471 + day * 24 + hour, 0] = month_data[month][
                9, day * 24 + hour + 9]  # day * 24 + hour : day * 24 + hour + 9为0-8前闭后开，而day * 24 + hour + 9表示第9小时
# print(x)
# print(y)
import math

x_train_set = x[: math.floor(len(x) * 0.8), :]  # 80%用来做training set，floor为向下取整ceil为向上取整
y_train_set = y[: math.floor(len(y) * 0.8), :]
x_validation = x[math.floor(len(x) * 0.8):, :]  # 80%用来做validation set
y_validation = y[math.floor(len(y) * 0.8):, :]
'''print(x_train_set)
print(y_train_set)
print(x_validation)
print(y_validation)
print(len(x_train_set))#共12*471=5652*0.8=4521.6，floor(4521.6）=4521，所以为[0,4251)共4251个数据
print(len(y_train_set))
print(len(x_validation))
print(len(y_validation))
'''

dim = 18 * 9 + 1
w = np.zeros([dim, 1])  # 产生一个163*1的权重矩阵，则w1表示的为b

x = np.concatenate((np.ones([12 * 471, 1]), x), axis=1).astype(float)#axis=0表示在0维拼接，在行数上加，axis=1表示在列上拼（加一列），因为常数项的存在，所以多加一项
#print(x)
#print(x.shape)
learning_rate = 100#学习速率
iter_time = 1000#迭代次数
adagrad = np.zeros([dim, 1])#存储每一次梯度的平方的和
eps = 0.0000000001#eps是避免adagrad的分母为0而加的极小值通常为1e-8
for t in range(iter_time):
    loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, 2)) / 471 / 12)  # rmse（ Root Mean Square Error）均方根误差，就是求完均方误差后再开根号，power（a，b）是对a求b次方
    if (t % 100 == 0):
        print(str(t) + ":" + str(loss))#每迭代100次显示一次Loss的大小
    gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y)  # 梯度，就是斜率，对Loss函数求导的结果
    adagrad += gradient ** 2#gradient的2次幂
    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)#sqrt开二次方
np.save('model/weight.npy', w)#把训练好的w参数保存到weight.npy

data = pd.read_csv('csv/test.csv',header=None, encoding='big5')
data = data.iloc[:, 2:]
print(data)
data[data == 'NR'] = 0
test_data = data.to_numpy()  # 将DataFrame的数据转为Numpy Array
print(test_data[0])
print(len(test_data))
row_test=int(len(test_data)/18)
x_test = np.empty([row_test, 18 * 9], dtype=float)
for i in range(row_test):
    x_test[i, :] = test_data[i*18:(i+1)*18, :].reshape(1,-1)# reshape(行数，列数)，-1表示unspecified value为未指定的值，将数据整理成9*18=162列的输入参数，一共len(test_data)/18=240行（一行一个样本）
x_test = np.concatenate((np.ones([row_test, 1]), x_test), axis=1).astype(float)#axis=0表示在0维拼接，在行数上加，axis=1表示在列上拼（加一列），因为常数项的存在，所以多加一项
print(x_test)
print(x_test.shape)
w = np.load('model/weight.npy')#163维的向量
print(w)
y_test = np.empty([12 * 471, 1], dtype=float)
y_test=np.dot(x_test,w)
print(y_test)

#保存到csv文件中
import csv
with open('csv/submit.csv', mode='w', newline='') as submit_file:#类似于try。。。except。。。finally
    csv_writer = csv.writer(submit_file)
    header = ['id', 'value']
    print(header)
    csv_writer.writerow(header)#先把表头写入
    for i in range(row_test):
        row = ['id_' + str(i), y_test[i][0]]
        csv_writer.writerow(row)#再把数据写入
        print(row)


```







