# 数据预处理之One-Hot Encoding

看到One-Hot-Encoding发现网上大多数说明都是来自于同一个例子，最后结果感觉出的好突兀，因此这里总结一下。

很多机器学习任务中，特征并不总是连续值，有可能是分类值。

考虑以下三个特征：

> ["male", "female"]
>
> ["from Europe", "from US", "from Asia"]
>
> ["uses Firefox", "uses Chrome", "uses Safari", "uses Internet Explorer"]

如果将上述特征用数字表示，效率会高很多。例如：

> ["male", "from US", "uses Internet Explorer"] 表示为[0, 1, 3]
>
> ["female", "from Asia", "uses Chrome"]表示为[1, 2, 1]

但是，转化为数字表示后，上述数据不能直接用在我们的分类器中。因为，分类器往往默认数据数据是连续的，并且是有序的。但按上述表示的数字并不有序的，而是随机分配的。

## One-Hot Encoding

解决上述问题的一种方法是采用One-Hot Encoding。

独热编码，又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都有它独立的寄存器位，并且在任意时候，其中只有一位有效。

例如：

> 自然状态码为：000,001,010,011,100,101
>
> 独热编码为：000001,000010,000100,001000,010000,100000

可以这样理解，对于每一个特征，如果它有m个可能值，那么经过独热编码后，就变成了m个二元特征。并且，这些特征互斥，每次只有一个激活。因此，数据会变成稀疏的。

这样做的好处主要有：

1. 解决了分类器不好处理属性数据的问题
2. 在一定程度上也起到了扩充特征的作用

基于python和Scikit-learn的一个简单例子：



```csharp
encoder = preprocessing.OneHotEncoder()
encoder.fit([
    [0, 2, 1, 12],
    [1, 3, 5, 3],
    [2, 3, 2, 12],
    [1, 2, 4, 3]
])
encoded_vector = encoder.transform([[2, 3, 5, 3]]).toarray()
print("\n Encoded vector =", encoded_vector)
```

输出结果：

> Encoded vector = [[ 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0.]]

分析：



```css
4个特征：
第一个特征（即为第一列）为[0,1,2,1] ，其中三类特征值[0,1,2]，因此One-Hot Code可将[0,1,2]表示为:[100,010,001]
同理第二个特征列可将两类特征值[2,3]表示为[10,01]
第三个特征将4类特征值[1,2,4,5]表示为[1000,0100,0010,0001]
第四个特征将2类特征值[3,12]表示为[10,01]

因此最后可将[2,3,5,3]表示为[0,0,1,0,1,0,0,0,1,1,0]
```

# L1，L2正则化

https://blog.csdn.net/jinping_shi/article/details/52433975

