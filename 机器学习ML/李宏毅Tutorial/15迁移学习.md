### 写在开头：

[迁移学习教程](https://blog.csdn.net/SunshineSki/article/details/84086760?utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control&dist_request_id=1328769.81757.16177812390848861&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.control)

[莫烦的tensorflow教程](https://www.bilibili.com/video/av16001891?p=44&spm_id_from=pageDriver)

[莫烦的tensorflow代码](https://github.com/MorvanZhou/Tensorflow-Tutorial)

# 1.Introduction

我们一直听过一句话叫，“如果说我看得比别人更远些，那是因为我站在巨人的肩膀上。（If I have seen further, it is by standing on the shoulders of giants.）”。“站在巨人的肩膀上”，不仅能看得更远,还能看到更多。这也用来表达我们要善于学习先辈的经验, 一个人的成功往往还取决于先辈们累积的知识。这句话, 放在机器学习中, 这就是今天要说的迁移学习（transfer learning）。

# 2.Development of Machine Learning

现在的机器人视觉已经非常先进了,有些甚至超过了人类，99.99%的识别准确率都不在话下。这样的成功，依赖于强大的机器学习技术，其中，神经网络成为了领军人物。而 CNN 等，像人一样拥有千千万万个神经联结的结构，为这种成功贡献了巨大力量。但是为了更厉害的CNN，我们的神经网络设计，也从简单的几层网络，变得越来越多，越来越多，越来越多… 为什么会越来越多?

因为计算机硬件, 比如GPU变得越来越强大，能够更快速地处理庞大的信息。在同样的时间内，机器能学到更多东西。可是，不是所有人都拥有这么庞大的计算能力，而且有时候面对类似的任务时，我们希望能够借鉴已有的资源。

# 3.What is transfer learning ？

这就好比，Google 和百度的关系，facebook和人人的关系，KFC和麦当劳的关系， 同一类型的事业，不用自己完全从头做，借鉴对方的经验，往往能节省很多时间。有这样的思路，我们也能偷偷懒，不用花时间重新训练一个无比庞大的神经网络, 借鉴借鉴一个已经训练好的神经网络就行。

迁移学习是深度学习中十分强大的理念之一，有的时候神经网络可以从一个任务中习得知识，并将这些知识应用到另一个独立的任务中。所以例如，也许你已经训练好一个神经网络，能够识别像猫这样的对象，然后使用那些知识，或者部分习得的知识去帮助您更好地阅读 x 射线扫描图，这就是所谓的迁移学习。如果你要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开始，如果你下载别人已经训练好网络结构的权重，你通常能够进展的相当快，用这个作为预训练，然后转换到你感兴趣的任务上。

> 计算机视觉的研究社区非常喜欢把许多数据集上传到网上，如果你听说过，比如 ImageNet，MS COCO，或者 Pascal 类型的数据集，这些都是不同数据集的名字，它们都是由大家上传到网络的，并且有大量的计算机视觉研究者已经用这些数据集训练过他们的算法了。有时候这些训练过程需要花费好几周，并且需要很多的GPU，其它人已经做过了，并且经历了非常痛苦的寻最优过程，这就意味着你可以下载花费了别人好几周甚至几个月而做出来的开源的权重参数，把它当作一个很好的初始化用在你自己的神经网络上。

# 4.How to transfer ?

第一个引用[莫凡大神](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/5-16-A-tranfer-learning/)的一个例子:

[scikit-image是一个处理图像的模块](https://scikit-image.org)

